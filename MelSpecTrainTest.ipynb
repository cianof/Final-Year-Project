{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MelSpecTrainTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESSeUZlM0XjQ"
      },
      "source": [
        "# Need to install these if running on Google Colab as they don't come automatically installed\n",
        "!pip3 install torchaudio\n",
        "!pip3 install torchinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLYT-zpmxiq5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from os.path import isdir, join\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from torch.autograd import Variable\n",
        "import torchaudio\n",
        "import torch\n",
        "import torchinfo\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "def plot_tensor(x, ar=8):\n",
        "    for i in range(x.shape[0]):\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "        ax.imshow(x[i], aspect='auto')\n",
        "        fig.set_figwidth(100)\n",
        "        fig.set_figheight(200)\n",
        "        ax.set_aspect(ar)\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YWIuNc5EYH_"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXlhXW6mxsnJ"
      },
      "source": [
        "#Run this if don't already have dataset downloaded or if on Colab\n",
        "data_dir = pathlib.Path('/content/data')\n",
        "if not data_dir.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'speech_commands_v0.02.tar.gz',\n",
        "      origin=\"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\",\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPqahve5xiq8"
      },
      "source": [
        "# data_dir='C:/Users/cferr/Documents/4th Year/FYP Data/speech_commands_v0.02'\n",
        "keywords = [name for name in listdir(data_dir) if isdir(join(data_dir, name))]\n",
        "#remove bg noise as it not a keyword\n",
        "keywords.remove('_background_noise_')\n",
        "print(keywords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWn7_Mz0xiq9"
      },
      "source": [
        "word2index = {\n",
        "    # core words\n",
        "    \"backward\": 0,\n",
        "    \"bed\": 1,\n",
        "    \"bird\": 2,\n",
        "    \"cat\": 3,\n",
        "    \"dog\": 4,\n",
        "    \"down\": 5,\n",
        "    \"eight\": 6,\n",
        "    \"five\": 7,\n",
        "    \"follow\": 8,\n",
        "    \"forward\": 9,\n",
        "    \"four\": 10,\n",
        "    \"go\": 11,\n",
        "    \"happy\": 12,\n",
        "    \"house\": 13,\n",
        "    \"learn\": 14,\n",
        "    \"left\": 15,\n",
        "    \"marvin\": 16,\n",
        "    \"nine\": 17,\n",
        "    \"no\": 18,\n",
        "    \"off\": 19,\n",
        "    \"on\":20,\n",
        "    \"one\":21,\n",
        "    \"right\":22,\n",
        "    \"seven\":23,\n",
        "    \"sheila\":24,\n",
        "    \"six\":25,\n",
        "    \"stop\":26,\n",
        "    \"three\":27,\n",
        "    \"tree\":28,\n",
        "    \"two\":29,\n",
        "    \"up\":30,\n",
        "    \"visual\":31,\n",
        "    \"wow\":32,\n",
        "    \"yes\":33,\n",
        "    \"zero\":34\n",
        "}\n",
        "\n",
        "index2word = [word for word in word2index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbNN_a7Bxiq-"
      },
      "source": [
        "num_classes = len(keywords)\n",
        "#helps oversampling of certain keywords by setting a max sample amount\n",
        "# num_samples_per_class = 4500\n",
        "speech_commands_dataset_basepath = Path(data_dir)\n",
        "\n",
        "samples = []\n",
        "classes =  []\n",
        "\n",
        "for word_class in word2index:\n",
        "    folder = speech_commands_dataset_basepath / word_class # folder for each word - looks like ' content/data/backward '\n",
        "    count = 0\n",
        "    for file in folder.iterdir(): # iterate over all files in the folder\n",
        "        #there are a few samples which aren't exactly 1 s long in the dataset.\n",
        "        if file.stat().st_size == 32044:\n",
        "            samples.append(file) # store path of sample file\n",
        "            classes.append(word2index[word_class]) # append word class index to list\n",
        "            count +=1\n",
        "            \n",
        "classes = np.array(classes, dtype=np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mix6_7k-xiq-"
      },
      "source": [
        "#split the data into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_classes, test_classes = train_test_split(samples, classes,\n",
        "                                                                      test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOm6U3yuqhyb"
      },
      "source": [
        "s = []\n",
        "s.append(str(train_data[1]))\n",
        "s.append(str(train_data[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "308fwxP0S43q"
      },
      "source": [
        "def transform(files):\n",
        "\n",
        "  mel_specgrams=[]\n",
        "  for fp in files:\n",
        "          waveform, sample_rate = torchaudio.load(fp)\n",
        "    \n",
        "          # normalize data\n",
        "          waveform -= waveform.mean()\n",
        "          waveform /= np.max((waveform.max(), -waveform.min()))\n",
        "        \n",
        "          mel_specgram = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, win_length=101, hop_length=8, n_mels=40)(waveform)\n",
        "          mel_specgrams.append(mel_specgram)\n",
        "\n",
        "  x = torch.cat(mel_specgrams)\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvD7PJYqYr7F"
      },
      "source": [
        "plot = transform(s)\n",
        "plot_tensor(plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-F6GXsTBtKM"
      },
      "source": [
        "#function to append the ground truth labels with its corresponding spectorgram tensor\n",
        "# needed to create DataLoader for input to model.\n",
        "def combinelabel(dataset, labels):\n",
        "  combined = []\n",
        "  labels=Variable(torch.from_numpy(labels).float())\n",
        "  for i in range(len(dataset)):\n",
        "    combined.append([str(dataset[i]), labels[i]])\n",
        "  return combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2cDg6sFbjPj"
      },
      "source": [
        "train_data_comb = combinelabel(train_data, train_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ30NVcWbY6G"
      },
      "source": [
        "#taking 10% of the training data aas a validation set:\n",
        "val_length = int(len(train_data_comb) * 0.1)\n",
        "print(val_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "areyIfuiYKHJ"
      },
      "source": [
        "validation_data_combine = train_data_comb[-val_length:]\n",
        "train_data_comb = train_data_comb[:-val_length]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-3LkRLYb2im"
      },
      "source": [
        "len(train_data_comb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l2EImaBcXUL"
      },
      "source": [
        "test_data_comb = combinelabel(test_data, test_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUsUNJxjw3rm"
      },
      "source": [
        "Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkNiwnsOxirC"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(train_data_comb, batch_size=128,\n",
        "                                          shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwHVspOzNJTk"
      },
      "source": [
        "len(trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66aVjclScTV3"
      },
      "source": [
        "validationloader = torch.utils.data.DataLoader(validation_data_combine, batch_size=128,\n",
        "                                          shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsX_TPo8eiqv"
      },
      "source": [
        "testloader = torch.utils.data.DataLoader(test_data_comb, batch_size=128,\n",
        "                                          shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hSmgxk8wj62"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ud-0e8IxirB"
      },
      "source": [
        "def DSConvLayer(c_in, c, k, s):\n",
        "    depth_conv = torch.nn.Conv1d(in_channels=c_in, out_channels=c_in, kernel_size=k, stride=2, groups=c_in)\n",
        "    point_conv = torch.nn.Conv1d(in_channels=c_in, out_channels=c, kernel_size=1, stride=1)\n",
        "    return torch.nn.Sequential(depth_conv, point_conv, torch.nn.ReLU(), torch.nn.BatchNorm1d(c), torch.nn.AvgPool1d(s), torch.nn.Dropout(0.1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK9onHPpxirB"
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.BatchNorm1d(40),\n",
        "    DSConvLayer(40,160,25,2), \n",
        "    DSConvLayer(160,160,9,1), \n",
        "    DSConvLayer(160,160,9,1), \n",
        "    DSConvLayer(160,160,9,1), \n",
        "    DSConvLayer(160,160,9,1), \n",
        "    torch.nn.AvgPool1d(24),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(160,35),\n",
        "    torch.nn.Softmax()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeAbkhsNrx4v"
      },
      "source": [
        "model=model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_zT_x0NxKsy"
      },
      "source": [
        "View the Model using torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpZQqp3DqeH_"
      },
      "source": [
        "samp = transform(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQygceEBxirB"
      },
      "source": [
        "# x_sample =x[0:1,:,:]\n",
        "# print(x.shape)\n",
        "torchinfo.summary(model, input_size=samp.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlHdpQiWjxP_"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZw618zYjwtf"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl7J1zKr-Wgy"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#declare loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzgzuP0UjZLI"
      },
      "source": [
        "epochs=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcmJqnOVi-AC"
      },
      "source": [
        "min_valid_loss = np.inf\n",
        "for e in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()     # Optional when not using Model Specific layer\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "        data = transform(data)\n",
        "        data = data.to(device)\n",
        "\n",
        "   \n",
        "        target = target.to(device)\n",
        "        target = target.type(torch.LongTensor)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output,target)\n",
        "        writer.add_scalar(\"Loss/train\", loss, e)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss = loss.item()\n",
        "    \n",
        "    valid_loss = 0.0\n",
        "    model.eval()     # Optional when not using Model Specific layer\n",
        "    for data, target in validationloader:\n",
        "        data = transform(data)\n",
        "\n",
        "        data = data.to(device)\n",
        "        output = model(data)\n",
        "        target = target.type(torch.LongTensor)\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output,target)\n",
        "        writer.add_scalar(\"Loss/val\", loss, e)\n",
        "        valid_loss = loss.item()\n",
        "\n",
        "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss} \\t\\t Validation Loss: {valid_loss}')\n",
        "    if min_valid_loss > valid_loss:\n",
        "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
        "        min_valid_loss = valid_loss\n",
        "        # Saving State Dict\n",
        "        torch.save(model.state_dict(), 'saved_model_melspec.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zSsyAfWkBkr"
      },
      "source": [
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC4-gr0M8oz5"
      },
      "source": [
        "# Testing Trained Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P10y0D3e56Un"
      },
      "source": [
        "model_load = model\n",
        "model_load.load_state_dict(torch.load('Trained_Models/saved_model_melspec.pth'))\n",
        "model_load.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJfPdxXR-WDZ"
      },
      "source": [
        "def test(model, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data, target in testloader:\n",
        "        target = target.to(device)\n",
        "        data = transform(data)\n",
        "\n",
        "        data = data.to(device)\n",
        "        output = model(data)\n",
        "\n",
        "        pred = pred=torch.max(output,dim=1)[1]\n",
        "        \n",
        "        correct+= (pred == target).float().sum() \n",
        "\n",
        "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(testloader.dataset)} ({100. * correct / len(testloader.dataset):.2f}%)\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X0NwZqW7FZv"
      },
      "source": [
        "test(model_load, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuaxshQNxgUg"
      },
      "source": [
        "# Example to Show how a convolution can be used as the first layer of 'pre-processing'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lnodsQ6xirC"
      },
      "source": [
        "input_conv = torch.nn.Conv1d(in_channels=1, out_channels=40, kernel_size=101, stride=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C68bjSfxirC"
      },
      "source": [
        "print(input_conv(p).shape)\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWPkGDqrxirC"
      },
      "source": [
        "model_s = torch.nn.Sequential(input_conv, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwvu1GK-xirC"
      },
      "source": [
        "print(x.shape)\n",
        "torchinfo.summary(model_s, input_size=p.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}