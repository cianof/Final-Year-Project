{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ODL_Linear_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4-u5RQLeOIW"
      },
      "source": [
        "#### Below is the retraining of the SINCCONV with only 34 keywords. The ODL implementation can be found under the 'On-Line Learning' section below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kYOeNBJ2jAO"
      },
      "source": [
        "# !pip install torchinfo\n",
        "# !pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWdw1mA_2d4t"
      },
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "\n",
        "from torchinfo import summary\n",
        "import sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import IPython.display as ipd\n",
        "import os\n",
        "import soundfile as sf\n",
        "from os import listdir\n",
        "from os.path import isdir, join\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e5W5ghreOIo"
      },
      "source": [
        "#should be  >1.2\n",
        "#pip install --upgrade pandas\n",
        "# pd.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viYK8yo-4W6C"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l70qU9_7_Ja1"
      },
      "source": [
        "# device ='cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z1QYi3E21FJ"
      },
      "source": [
        "# data_dir = pathlib.Path('/content/data')\n",
        "# if not data_dir.exists():\n",
        "#   tf.keras.utils.get_file(\n",
        "#       'speech_commands_v0.02.tar.gz',\n",
        "#       origin=\"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\",\n",
        "#       extract=True,\n",
        "#       cache_dir='.', cache_subdir='data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45d_tp0x2d4u"
      },
      "source": [
        "# output_folder =str(output_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-tni9qB2d4u"
      },
      "source": [
        "data_dir = 'C:/Users/cferr/Documents/4th Year/FYP Data/speech_commands_v0.02/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsgOtAnD2d4v"
      },
      "source": [
        "keywords = [name for name in listdir(data_dir) if isdir(join(data_dir, name))]\n",
        "#remove bg noise as it not needed and requires extra pre-processing\n",
        "keywords.remove('_background_noise_')\n",
        "keywords.remove('zero')\n",
        "print(keywords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayO2PU5B2d4v"
      },
      "source": [
        "word2index = {\n",
        "    # core words\n",
        "    \"backward\": 0,\n",
        "    \"bed\": 1,\n",
        "    \"bird\": 2,\n",
        "    \"cat\": 3,\n",
        "    \"dog\": 4,\n",
        "    \"down\": 5,\n",
        "    \"eight\": 6,\n",
        "    \"five\": 7,\n",
        "    \"follow\": 8,\n",
        "    \"forward\": 9,\n",
        "    \"four\": 10,\n",
        "    \"go\": 11,\n",
        "    \"happy\": 12,\n",
        "    \"house\": 13,\n",
        "    \"learn\": 14,\n",
        "    \"left\": 15,\n",
        "    \"marvin\": 16,\n",
        "    \"nine\": 17,\n",
        "    \"no\": 18,\n",
        "    \"off\": 19,\n",
        "    \"on\":20,\n",
        "    \"one\":21,\n",
        "    \"right\":22,\n",
        "    \"seven\":23,\n",
        "    \"sheila\":24,\n",
        "    \"six\":25,\n",
        "    \"stop\":26,\n",
        "    \"three\":27,\n",
        "    \"tree\":28,\n",
        "    \"two\":29,\n",
        "    \"up\":30,\n",
        "    \"visual\":31,\n",
        "    \"wow\":32,\n",
        "    \"yes\":33,\n",
        "}\n",
        "\n",
        "index2word = [word for word in word2index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3zjmADn2d4v"
      },
      "source": [
        "filenames = []\n",
        "y = []\n",
        "for word_class in word2index:\n",
        "    for files in listdir(join(data_dir, word_class)):\n",
        "        filenames.append(join(word_class, files))\n",
        "        y.append(word2index[word_class]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFZ6p3Uv2d4v"
      },
      "source": [
        "#create a dictionary of the filenames and labels\n",
        "combined_dict = dict(zip(filenames,y))\n",
        "#save that dictionary\n",
        "np.save('files_dict', combined_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64rHEYLj2d4w"
      },
      "source": [
        "train_data, validation_data, train_classes, validation_classes = train_test_split(filenames, y,\n",
        "                                                                      test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk-mGaJP2d4w"
      },
      "source": [
        "def getLists(files_in, output_name):\n",
        "  MyFile=open(output_name,'w')\n",
        "\n",
        "  for element in files_in:\n",
        "      MyFile.write(element)\n",
        "      MyFile.write('\\n')\n",
        "  MyFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4f9_sRq2d4w"
      },
      "source": [
        "getLists(filenames, 'fileslist.scp')\n",
        "getLists(validation_data, 'test.scp')\n",
        "getLists(train_data, 'train.scp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeTThrto2d4w"
      },
      "source": [
        "data_folder = data_dir\n",
        "outdim = len(keywords)\n",
        "lab_dict = np.load('files_dict.npy', allow_pickle=True).item()\n",
        "\n",
        "lr=0.001\n",
        "batch_size=128\n",
        "Batch_dev=128\n",
        "N_epochs=100\n",
        "N_batches=665\n",
        "N_eval_epoch=8\n",
        "seed=42\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJDmnljH2d4x"
      },
      "source": [
        "def ReadList(list_file):\n",
        " f=open(list_file,\"r\")\n",
        " lines=f.readlines()\n",
        " list_sig=[]\n",
        " for x in lines:\n",
        "    list_sig.append(x.rstrip())\n",
        " f.close()\n",
        " return list_sig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dza-2Z7K2d4x"
      },
      "source": [
        "wav_lst_tr=ReadList('train.scp')\n",
        "snt_tr=len(wav_lst_tr)\n",
        "# test list\n",
        "wav_lst_te=ReadList('test.scp')\n",
        "snt_te=len(wav_lst_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PCiJDpD2d4x"
      },
      "source": [
        "wlen=16000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEu5m5kT2d4y"
      },
      "source": [
        "### SincConv module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK7ryaaj2d4y"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class SincConv(torch.nn.Module):\n",
        "    @staticmethod\n",
        "    def to_mel(hz):\n",
        "        return 2595 * np.log10(1 + hz / 700)\n",
        "\n",
        "    @staticmethod\n",
        "    def to_hz(mel):\n",
        "        return 700 * (10 ** (mel / 2595) - 1)\n",
        "\n",
        "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1, stride=1, padding=0, min_low_hz=50, min_band_hz=50):\n",
        "        super(SincConv,self).__init__()\n",
        "\n",
        "        if in_channels != 1:\n",
        "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
        "            raise ValueError(msg)\n",
        "\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
        "        if kernel_size%2==0:\n",
        "            self.kernel_size=self.kernel_size+1\n",
        "        # parameters    \n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.sample_rate = sample_rate\n",
        "        self.min_low_hz = min_low_hz\n",
        "        self.min_band_hz = min_band_hz\n",
        "        # initialize filterbanks such that they are equally spaced in Mel scale\n",
        "        low_hz = 30\n",
        "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n",
        "        mel = np.linspace(self.to_mel(low_hz), self.to_mel(high_hz), self.out_channels + 1)\n",
        "        hz = self.to_hz(mel)\n",
        "        # filter lower frequency (out_channels, 1)\n",
        "        self.low_hz_ = torch.nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\n",
        "    \n",
        "        #\n",
        "        # self.low_hz_ =torch.Tensor(hz[:-1]).view(-1, 1).to(device)\n",
        "        # filter frequency band (out_channels, 1)\n",
        "        self.band_hz_ = torch.nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\n",
        "        # self.band_hz_ =torch.Tensor(np.diff(hz)).view(-1, 1).to(device)\n",
        "\n",
        "        # Hamming window\n",
        "        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\n",
        "        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size);\n",
        "        # (1, kernel_size/2)\n",
        "        n = (self.kernel_size - 1) / 2.0\n",
        "        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\n",
        "\n",
        "    def forward(self, waveforms):\n",
        "        self.n_ = self.n_.to(waveforms.device)\n",
        "        self.window_ = self.window_.to(waveforms.device)\n",
        "        low = self.min_low_hz  + torch.abs(self.low_hz_)\n",
        "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2)\n",
        "        band=(high-low)[:,0]\n",
        "        \n",
        "        f_times_t_low = torch.matmul(low, self.n_)\n",
        "        f_times_t_high = torch.matmul(high, self.n_)\n",
        "\n",
        "        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations. \n",
        "        band_pass_center = 2*band.view(-1,1)\n",
        "        band_pass_right= torch.flip(band_pass_left,dims=[1])\n",
        "        \n",
        "        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1)\n",
        "        band_pass = band_pass / (2*band[:,None])\n",
        "\n",
        "        self.filters = (band_pass).view(self.out_channels, 1, self.kernel_size)\n",
        "        return torch.nn.functional.conv1d(waveforms, self.filters, stride=self.stride, padding=self.padding, dilation=1, bias=None, groups=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHjjVTEc2d4y"
      },
      "source": [
        "### LogAbs Acitvation Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XpfA_IC2d4y"
      },
      "source": [
        "class LogAbs(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogAbs,self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.log(torch.abs(x) + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISIdXA5B2d4z"
      },
      "source": [
        "### Sinc and Separable Conv Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2K9JqHM2d4z"
      },
      "source": [
        "def SincConvBlock(c, k, s, sample_rate=16000):\n",
        "    sinc_conv = SincConv(out_channels=c, kernel_size=k, sample_rate=sample_rate, in_channels=1, stride=s, padding=k//2)\n",
        "    avg_pool = torch.nn.AvgPool1d(kernel_size=2, stride=2)\n",
        "    return torch.nn.Sequential(sinc_conv, LogAbs(), torch.nn.BatchNorm1d(c), avg_pool)\n",
        "\n",
        "def DSConvBlock(c_in, c, k, s):\n",
        "    depth_conv = torch.nn.Conv1d(in_channels=c_in, out_channels=c_in, kernel_size=k, stride=s, padding=k//2, groups=c_in)\n",
        "    point_conv = torch.nn.Conv1d(in_channels=c_in, out_channels=c, kernel_size=1, stride=1)\n",
        "    return torch.nn.Sequential(depth_conv, point_conv, torch.nn.ReLU(), torch.nn.BatchNorm1d(c), torch.nn.AvgPool1d(2), torch.nn.Dropout(0.1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGU7b3if2d4z"
      },
      "source": [
        "def batch_gen(batch_size,data_folder,wav_lst,N_snt,wlen,lab_dict):\n",
        "    sig_batch=torch.zeros([batch_size,1, wlen])\n",
        "    lab_batch=torch.zeros(batch_size)\n",
        "    snt_id_arr=torch.randint(0, N_snt, (batch_size,))\n",
        "    \n",
        "    waveforms=[]\n",
        "    for i in range(batch_size):\n",
        "        waveform, sample_rate = torchaudio.load(str(data_folder)+'/'+wav_lst[snt_id_arr[i]])\n",
        "\n",
        "        #ensure all waveforms are padded to a length of 16000\n",
        "        snt_len=waveform.shape[1]\n",
        "        if(snt_len < 16000):\n",
        "            target = torch.zeros((1,16000))\n",
        "            target[:, :snt_len] = waveform\n",
        "            waveform=target \n",
        "        waveforms.append(waveform)\n",
        "        lab_batch[i]=lab_dict[wav_lst[snt_id_arr[i]]]\n",
        "    s = torch.cat(waveforms).unsqueeze(1) # Audio samples, Feature first (1 since mono)\n",
        "    return s, lab_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJjD6XUMrDL1"
      },
      "source": [
        "Test the batch_gen function to ensure its working as intended"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXHEJrOl2d4z"
      },
      "source": [
        "[inp,lab]=batch_gen(3,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7S6vJsO2d40"
      },
      "source": [
        "### Combine all elements of the model as seen in Mittermaier et. al"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HUTgT_y2d41"
      },
      "source": [
        "sinc_conv_model = torch.nn.Sequential(\n",
        "    SincConvBlock(c=40, k=101, s=8),\n",
        "    DSConvBlock(40,160,25,2), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    torch.nn.AvgPool1d(15),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(160,35),\n",
        "    torch.nn.Softmax(dim=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKhX1ivH9vss"
      },
      "source": [
        "print(sinc_conv_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huZkrQSB2d41"
      },
      "source": [
        "[inp,lab]=batch_gen(1,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict)\n",
        "sinc_conv_model=sinc_conv_model.to(device)\n",
        "inp = inp.to(device)\n",
        "summary(sinc_conv_model, input_data=[inp])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJWPixI62d41"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrXySs3r2d41"
      },
      "source": [
        "sinc_model=sinc_conv_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5mQqcLz2d41"
      },
      "source": [
        "n = count_parameters(sinc_model)\n",
        "print(\"Number of parameters: %s\" % n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9o4NhFtxyya"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSE1DCyqxjnP"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7UcEj9v2d42"
      },
      "source": [
        "cost = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjdaBqTe2d42"
      },
      "source": [
        "optimizer = optim.Adam(sinc_model.parameters(), lr=lr, eps=1e-8)\n",
        "log_interval = 800"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2MS2q5_5whQ"
      },
      "source": [
        "def train(model, epoch, log_interval):\n",
        "    # model=model.to(device)\n",
        "    model.train()\n",
        "      \n",
        "    for i in range(N_batches):\n",
        "        [inp,target]=batch_gen(batch_size,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict)\n",
        "\n",
        "        inp = inp.to(device)\n",
        "        \n",
        "\n",
        "        target = target.type(torch.LongTensor)\n",
        "        target = target.to(device)\n",
        "        output = model(inp)\n",
        "          # print(type(output))\n",
        "          # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
        "        loss = cost(output, target)\n",
        "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "          # print training stats\n",
        "        if i % log_interval == 0:\n",
        "              print(f\"Train Epoch: {epoch} [{i * len(inp)}/{snt_tr} ({100. * i / N_batches:.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
        "\n",
        "          # update progress bar\n",
        "        pbar.update(pbar_update)\n",
        "          # record loss\n",
        "        losses.append(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f62HUg6sH4Xs"
      },
      "source": [
        "N_batches_te=170"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKmCaYOi52eF"
      },
      "source": [
        "def test(model, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for i in range(N_batches_te):\n",
        "        [data,target]=batch_gen(batch_size,data_folder,wav_lst_te,snt_te,wlen,lab_dict)\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        pred = pred=torch.max(output,dim=1)[1]\n",
        "        \n",
        "        correct+= (pred == target).float().sum() \n",
        "\n",
        "        # update progress bar\n",
        "        pbar.update(pbar_update)\n",
        "    accuracy.append(correct/(batch_size*N_batches_te))\n",
        "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{(batch_size*N_batches_te)} ({100. * correct /snt_te:.2f}%)\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d1vQe0r56bJ"
      },
      "source": [
        "#controls how often training updates are printed on the screen\n",
        "log_interval = 300\n",
        "n_epoch = 22\n",
        "\n",
        "pbar_update = 1 / snt_te+snt_tr\n",
        "losses = []\n",
        "accuracy=[]\n",
        "\n",
        "with tqdm(total=n_epoch) as pbar:\n",
        "    for epoch in range(1, n_epoch + 1):\n",
        "        train(sinc_model, epoch, log_interval)\n",
        "        test(sinc_model, epoch)\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV-_72GCxUZJ"
      },
      "source": [
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhwIo6Sqt9n_"
      },
      "source": [
        "torch.save(sinc_model.state_dict(), 'Trained_Models/model_34.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfoEkc3xR4fk"
      },
      "source": [
        "## On-line Learning / One-shot Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNGk72oc_Buo"
      },
      "source": [
        "feature_mapping_model = torch.nn.Sequential(\n",
        "    SincConvBlock(c=40, k=101, s=8),\n",
        "    DSConvBlock(40,160,25,2), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    torch.nn.AvgPool1d(15),\n",
        "    torch.nn.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6JsyVzGShQZ"
      },
      "source": [
        "model_tmp = sinc_conv_model\n",
        "model_tmp.load_state_dict(torch.load('Trained_Models/model_34.pth', map_location=torch.device('cpu')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZWxDKqt_Uuo"
      },
      "source": [
        "feature_mapping_model = torch.nn.Sequential(*[model_tmp[i] for i in range(8)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8sNTmbMGL4u"
      },
      "source": [
        "feature_mapping_model = feature_mapping_model.to('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HsGRkM9Tgq5"
      },
      "source": [
        "feature_mapping_model(inp).cpu().detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGG7yvD5USD_"
      },
      "source": [
        "Next step is to create vectors for all the existing keywords but also for the unseen keyword of 'zero' <br> Then need to create a Y vector where every keyword but 'zero' has a value of 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AnLD_zs6LGv"
      },
      "source": [
        "def batch_gen_zero(batch_size,data_folder,wav_lst,N_snt,wlen,lab_dict):\n",
        "    sig_batch=torch.zeros([batch_size,1, wlen])\n",
        "    lab_batch=torch.zeros(batch_size)\n",
        "    snt_id_arr=torch.arange(0, N_snt)\n",
        "    \n",
        "    waveforms=[]\n",
        "    for i in range(batch_size):\n",
        "        waveform, sample_rate = torchaudio.load(str(data_folder)+'/'+wav_lst[snt_id_arr[i]])\n",
        "\n",
        "        #ensure all waveforms are padded to a length of 16000\n",
        "        snt_len=waveform.shape[1]\n",
        "        if(snt_len < 16000):\n",
        "            target = torch.zeros((1,16000))\n",
        "            target[:, :snt_len] = waveform\n",
        "            waveform=target \n",
        "        waveforms.append(waveform)\n",
        "    s = torch.cat(waveforms).unsqueeze(1) # Audio samples, Feature first (1 since mono)\n",
        "    return s, lab_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQgSNO_yX92V"
      },
      "source": [
        "zero_dict = {'zero':1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OApMWUjrX8f4"
      },
      "source": [
        "filename_zero = []\n",
        "y_zero = []\n",
        "for word_class in zero_dict:\n",
        "    for files in listdir(join(data_dir, word_class)):\n",
        "        filename_zero.append(join(word_class, files))\n",
        "        y_zero.append(zero_dict[word_class]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IocC3oHl1nmY"
      },
      "source": [
        "zero_train = filename_zero[:-800]\n",
        "zero_test = filename_zero[-800:]\n",
        "zero_train_y = y_zero[:-800]\n",
        "zero_test_y = y_zero[-800:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epsNJy7aDU52"
      },
      "source": [
        "def make_matrix(filelist):\n",
        "  temp =[]\n",
        "  for i in range(len(filelist)):\n",
        "    inp, _ = batch_gen_zero(1,data_folder,filelist, len(filelist),wlen, lab_dict)\n",
        "    inp = inp.to('cpu')\n",
        "\n",
        "    temp.append(feature_mapping_model(inp).cpu().detach().numpy())\n",
        "\n",
        "  temp = np.array(temp)\n",
        "  temp = temp.squeeze(1)\n",
        "\n",
        "  return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEJmogjED9Ff"
      },
      "source": [
        "wav_list_reg = wav_lst_tr[:4000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnBSiHJdEEhJ"
      },
      "source": [
        "full_matrix = make_matrix(wav_list_reg)\n",
        "zero_matrix = make_matrix(filename_zero)\n",
        "full_matrix = np.append(full_matrix, zero_matrix,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEaO0zu7O2a5"
      },
      "source": [
        "# scaled_matrix = scaler.fit_transform(full_matrix)\n",
        "scaled_matrix= full_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNI51AtnHm6W"
      },
      "source": [
        "accuracies =[]\n",
        "sample_size =[]\n",
        "\n",
        "#we incrementally add 100 additional samples of 'zero' at each iteration\n",
        "# at each interation a new regression model is created and its score evaluated and stored\n",
        "for i in range(4100, len(full_matrix), 100):\n",
        "    resampled_matrix =[]\n",
        "    resampled_matrix = full_matrix[-i:]\n",
        "    resampled_y = y[-i:]\n",
        "    \n",
        "    train_matrix, test_matrix, train_classes, test_classes = train_test_split(resampled_matrix, resampled_y, test_size=0.2,\n",
        "                                                                              random_state=42, shuffle=True)\n",
        "    reg= LinearRegression(normalize=True)\n",
        "    reg.fit(train_matrix, train_classes)\n",
        "    accuracy = (reg.score(test_matrix, test_classes))\n",
        "    sample_size.append(i)\n",
        "    accuracies.append(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ0RFoGpeOI-"
      },
      "source": [
        "df = pd.DataFrame(columns=['Accuracy', 'No_Samples'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfau7nwreOI-"
      },
      "source": [
        "df['Accuracy'] = accuracies\n",
        "df['No_Samples'] = sample_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "PqQ7Z4iAeOI-"
      },
      "source": [
        "df.plot(x='No_Samples',y='Accuracy',xlabel='Total Number Samples', ylabel='Accuracy', grid=True, figsize=(12,8), \n",
        "        title='Accuracy vs Samples - Linear Regression', legend=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnIe3ZLPeOI-"
      },
      "source": [
        "resampled_matrix =[]\n",
        "resampled_matrix = full_matrix[-6100:]\n",
        "resampled_y = y[-6100:]\n",
        "    \n",
        "train_matrix, test_matrix, train_classes, test_classes = train_test_split(resampled_matrix, resampled_y, test_size=0.2,\n",
        "                                                                              random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzMckCVPHilx"
      },
      "source": [
        "reg= LinearRegression(normalize=True)\n",
        "reg.fit(train_matrix, train_classes)\n",
        "accuracy = (reg.score(test_matrix, test_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-0BVPyYeOI_"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxx9KdS6eOI_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}