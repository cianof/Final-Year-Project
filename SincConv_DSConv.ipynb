{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "SincConv-DSConv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kYOeNBJ2jAO"
      },
      "source": [
        "#needs to be run at every colab instance\n",
        "# !pip install torchinfo\n",
        "# !pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWdw1mA_2d4t"
      },
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "# from torchsummary import summary\n",
        "from torchinfo import summary\n",
        "\n",
        "import os\n",
        "import soundfile as sf\n",
        "from os import listdir\n",
        "from os.path import isdir, join\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viYK8yo-4W6C"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l70qU9_7_Ja1"
      },
      "source": [
        "# device ='cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnBzSKsZ2d4u"
      },
      "source": [
        "output_folder =  pathlib.Path('output')\n",
        "\n",
        "if not output_folder.exists():\n",
        "    os.mkdir(output_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z1QYi3E21FJ"
      },
      "source": [
        "data_dir = pathlib.Path('/content/data')\n",
        "if not data_dir.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'speech_commands_v0.02.tar.gz',\n",
        "      origin=\"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\",\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45d_tp0x2d4u"
      },
      "source": [
        "output_folder =str(output_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-tni9qB2d4u"
      },
      "source": [
        "# data_dir = 'C:/Users/cferr/Documents/4th Year/FYP Data/speech_commands_v0.02/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsgOtAnD2d4v"
      },
      "source": [
        "keywords = [name for name in listdir(data_dir) if isdir(join(data_dir, name))]\n",
        "#remove bg noise as it not needed and requires extra pre-processing\n",
        "keywords.remove('_background_noise_')\n",
        "print(keywords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayO2PU5B2d4v"
      },
      "source": [
        "word2index = {\n",
        "    # core words\n",
        "    \"backward\": 0,\n",
        "    \"bed\": 1,\n",
        "    \"bird\": 2,\n",
        "    \"cat\": 3,\n",
        "    \"dog\": 4,\n",
        "    \"down\": 5,\n",
        "    \"eight\": 6,\n",
        "    \"five\": 7,\n",
        "    \"follow\": 8,\n",
        "    \"forward\": 9,\n",
        "    \"four\": 10,\n",
        "    \"go\": 11,\n",
        "    \"happy\": 12,\n",
        "    \"house\": 13,\n",
        "    \"learn\": 14,\n",
        "    \"left\": 15,\n",
        "    \"marvin\": 16,\n",
        "    \"nine\": 17,\n",
        "    \"no\": 18,\n",
        "    \"off\": 19,\n",
        "    \"on\":20,\n",
        "    \"one\":21,\n",
        "    \"right\":22,\n",
        "    \"seven\":23,\n",
        "    \"sheila\":24,\n",
        "    \"six\":25,\n",
        "    \"stop\":26,\n",
        "    \"three\":27,\n",
        "    \"tree\":28,\n",
        "    \"two\":29,\n",
        "    \"up\":30,\n",
        "    \"visual\":31,\n",
        "    \"wow\":32,\n",
        "    \"yes\":33,\n",
        "    \"zero\":34\n",
        "}\n",
        "\n",
        "index2word = [word for word in word2index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3zjmADn2d4v"
      },
      "source": [
        "filenames = []\n",
        "y = []\n",
        "for word_class in word2index:\n",
        "    for files in listdir(join(data_dir, word_class)):\n",
        "        filenames.append(join(word_class, files))\n",
        "        y.append(word2index[word_class]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFZ6p3Uv2d4v"
      },
      "source": [
        "#create a dictionary of the filenames and labels\n",
        "combined_dict = dict(zip(filenames,y))\n",
        "#save that dictionary\n",
        "np.save('files_dict', combined_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64rHEYLj2d4w"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data_initial, test_data, train_classes_initial, validation_classes = train_test_split(filenames, y,\n",
        "                                                                      test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx_84Jmd6oPB"
      },
      "source": [
        "train_data, validation_data, train_classes, validation_classes =train_test_split(train_data_initial, train_classes_initial,\n",
        "                                                                      test_size=0.1, random_state=42, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk-mGaJP2d4w"
      },
      "source": [
        "def getLists(files_in, output_name):\n",
        "  MyFile=open(output_name,'w')\n",
        "\n",
        "  for element in files_in:\n",
        "      MyFile.write(element)\n",
        "      MyFile.write('\\n')\n",
        "  MyFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4f9_sRq2d4w"
      },
      "source": [
        "getLists(filenames, 'fileslist.scp')\n",
        "getLists(test_data, 'test.scp')\n",
        "getLists(train_data, 'train.scp')\n",
        "getLists(validation_data, 'val.scp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeTThrto2d4w"
      },
      "source": [
        "data_folder = data_dir\n",
        "outdim = len(keywords)\n",
        "lab_dict = np.load('files_dict.npy', allow_pickle=True).item()\n",
        "\n",
        "lr=0.001\n",
        "batch_size=128\n",
        "Batch_dev=128\n",
        "N_epochs=100\n",
        "N_batches=595\n",
        "N_eval_epoch=8\n",
        "seed=42\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJDmnljH2d4x"
      },
      "source": [
        "def ReadList(list_file):\n",
        " f=open(list_file,\"r\")\n",
        " lines=f.readlines()\n",
        " list_sig=[]\n",
        " for x in lines:\n",
        "    list_sig.append(x.rstrip())\n",
        " f.close()\n",
        " return list_sig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dza-2Z7K2d4x"
      },
      "source": [
        "wav_lst_tr=ReadList('train.scp')\n",
        "snt_tr=len(wav_lst_tr)\n",
        "# test list\n",
        "wav_lst_te=ReadList('test.scp')\n",
        "snt_te=len(wav_lst_te)\n",
        "#validation list\n",
        "wav_lst_val=ReadList('val.scp')\n",
        "snt_val=len(wav_lst_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZdYYwwRFUSG"
      },
      "source": [
        "snt_tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PCiJDpD2d4x"
      },
      "source": [
        "wlen=16000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEu5m5kT2d4y"
      },
      "source": [
        "### SincConv module\n",
        "based on https://github.com/mravanelli/SincNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK7ryaaj2d4y"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class SincConv(torch.nn.Module):\n",
        "    @staticmethod\n",
        "    def to_mel(hz):\n",
        "        return 2595 * np.log10(1 + hz / 700)\n",
        "\n",
        "    @staticmethod\n",
        "    def to_hz(mel):\n",
        "        return 700 * (10 ** (mel / 2595) - 1)\n",
        "\n",
        "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1, stride=1, padding=0, min_low_hz=50, min_band_hz=50):\n",
        "        super(SincConv,self).__init__()\n",
        "\n",
        "        if in_channels != 1:\n",
        "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
        "            raise ValueError(msg)\n",
        "\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
        "        if kernel_size%2==0:\n",
        "            self.kernel_size=self.kernel_size+1\n",
        "        # parameters    \n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.sample_rate = sample_rate\n",
        "        self.min_low_hz = min_low_hz\n",
        "        self.min_band_hz = min_band_hz\n",
        "        # initialize filterbanks such that they are equally spaced in Mel scale\n",
        "        low_hz = 30\n",
        "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n",
        "        mel = np.linspace(self.to_mel(low_hz), self.to_mel(high_hz), self.out_channels + 1)\n",
        "        hz = self.to_hz(mel)\n",
        "        # filter lower frequency (out_channels, 1)\n",
        "        self.low_hz_ = torch.nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\n",
        "        # self.low_hz_ =torch.Tensor(hz[:-1]).view(-1, 1).to(device)\n",
        "        # filter frequency band (out_channels, 1)\n",
        "        self.band_hz_ = torch.nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\n",
        "        # self.band_hz_ =torch.Tensor(np.diff(hz)).view(-1, 1).to(device)\n",
        "\n",
        "        # Hamming window\n",
        "        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\n",
        "        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size);\n",
        "        # (1, kernel_size/2)\n",
        "        n = (self.kernel_size - 1) / 2.0\n",
        "        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\n",
        "\n",
        "    def forward(self, waveforms):\n",
        "        self.n_ = self.n_.to(waveforms.device)\n",
        "        self.window_ = self.window_.to(waveforms.device)\n",
        "        low = self.min_low_hz  + torch.abs(self.low_hz_)\n",
        "        # low= low.to(device)\n",
        "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2)\n",
        "        # high=high.to(device)\n",
        "        band=(high-low)[:,0]\n",
        "        \n",
        "        # f_times_t_low = torch.matmul(low, self.n_).to(device)\n",
        "        # f_times_t_high = torch.matmul(high, self.n_).to(device)\n",
        "        f_times_t_low = torch.matmul(low, self.n_)\n",
        "        f_times_t_high = torch.matmul(high, self.n_)\n",
        "\n",
        "\n",
        "        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations. \n",
        "        band_pass_center = 2*band.view(-1,1)\n",
        "        band_pass_right= torch.flip(band_pass_left,dims=[1])\n",
        "        \n",
        "        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1)\n",
        "        band_pass = band_pass / (2*band[:,None])\n",
        "\n",
        "        self.filters = (band_pass).view(self.out_channels, 1, self.kernel_size)\n",
        "        return torch.nn.functional.conv1d(waveforms, self.filters, stride=self.stride, padding=self.padding, dilation=1, bias=None, groups=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHjjVTEc2d4y"
      },
      "source": [
        "### LogAbs Acitvation Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XpfA_IC2d4y"
      },
      "source": [
        "class LogAbs(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogAbs,self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.log(torch.abs(x) + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISIdXA5B2d4z"
      },
      "source": [
        "### Sinc and Depthwise Separable Conv Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2K9JqHM2d4z"
      },
      "source": [
        "def SincConvBlock(c, k, s, sample_rate=16000):\n",
        "    sinc_conv = SincConv(out_channels=c, kernel_size=k, sample_rate=sample_rate, in_channels=1, stride=s, padding=k//2)\n",
        "    avg_pool = torch.nn.AvgPool1d(kernel_size=2, stride=2)\n",
        "    return torch.nn.Sequential(sinc_conv, LogAbs(), torch.nn.BatchNorm1d(c), avg_pool)\n",
        "\n",
        "def DSConvBlock(c_in, c, k, s):\n",
        "    depth_conv = torch.nn.Conv1d(in_channels=c_in, out_channels=c_in, kernel_size=k, stride=s, padding=k//2, groups=c_in)\n",
        "    point_conv = torch.nn.Conv1d(in_channels=c_in, out_channels=c, kernel_size=1, stride=1)\n",
        "    return torch.nn.Sequential(depth_conv, point_conv, torch.nn.ReLU(), torch.nn.BatchNorm1d(c), torch.nn.AvgPool1d(2), torch.nn.Dropout(0.1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoEXa_hFLJM_"
      },
      "source": [
        "## Batch generator to extract waveforms "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGU7b3if2d4z"
      },
      "source": [
        "def batch_gen(batch_size,data_folder,wav_lst,N_snt,wlen,lab_dict):\n",
        "    sig_batch=torch.zeros([batch_size,1, wlen])\n",
        "    lab_batch=torch.zeros(batch_size)\n",
        "    snt_id_arr=torch.randint(0, N_snt, (batch_size,))\n",
        "    \n",
        "    waveforms=[]\n",
        "    for i in range(batch_size):\n",
        "        waveform, sample_rate = torchaudio.load(str(data_folder)+'/'+wav_lst[snt_id_arr[i]])\n",
        "\n",
        "        #ensure all waveforms are padded to a length of 16000\n",
        "        snt_len=waveform.shape[1]\n",
        "        if(snt_len < 16000):\n",
        "            target = torch.zeros((1,16000))\n",
        "            target[:, :snt_len] = waveform\n",
        "            waveform=target \n",
        "        waveforms.append(waveform)\n",
        "        lab_batch[i]=lab_dict[wav_lst[snt_id_arr[i]]]\n",
        "    s = torch.cat(waveforms).unsqueeze(1) # Audio samples, Feature first (1 since mono)\n",
        "    return s, lab_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJjD6XUMrDL1"
      },
      "source": [
        "Test the batch_gen function to ensure its working as intended"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXHEJrOl2d4z"
      },
      "source": [
        "[inp,lab]=batch_gen(3,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict)\n",
        "inp.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2tRO2Jt2d40"
      },
      "source": [
        "print(inp.shape, lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uybpanfj2d40"
      },
      "source": [
        "def plot_tensor(x, ar=8):\n",
        "    for i in range(x.shape[0]):\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "        ax.imshow(x[i].log2().numpy())\n",
        "        fig.set_figwidth(100)\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIiEpYGSDop2"
      },
      "source": [
        "Obersevation of spectrogram plots produced by the sinc-convolution layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMNGqVCu2d40"
      },
      "source": [
        "sinc_conv_block = SincConvBlock(c=40, k=101, s=8)\n",
        "sc = sinc_conv_block(inp).unsqueeze(1).detach()\n",
        "scc = sc.view(sc.size(0), -1)\n",
        "scc -= scc.min(1, keepdim=True)[0]\n",
        "scc /= scc.max(1, keepdim=True)[0]\n",
        "sc = scc.view(3, 1, 40, 1000).squeeze(1)\n",
        "print(sc.shape)\n",
        "plot_tensor(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7S6vJsO2d40"
      },
      "source": [
        "### Full Model. Based on Mittermaier et al."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HUTgT_y2d41"
      },
      "source": [
        "sinc_conv_model = torch.nn.Sequential(\n",
        "    SincConvBlock(c=40, k=101, s=8),\n",
        "    DSConvBlock(40,160,25,2), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    torch.nn.AvgPool1d(15),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(160,35),\n",
        "    torch.nn.Softmax(dim=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huZkrQSB2d41"
      },
      "source": [
        "[inp,lab]=batch_gen(1,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict)\n",
        "sinc_conv_model=sinc_conv_model.to(device)\n",
        "inp = inp.to(device)\n",
        "summary(sinc_conv_model, input_data=[inp])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJWPixI62d41"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrXySs3r2d41"
      },
      "source": [
        "model=sinc_conv_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5mQqcLz2d41"
      },
      "source": [
        "n = count_parameters(model)\n",
        "print(\"Number of parameters: %s\" % n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9o4NhFtxyya"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "LOG_DIR = \"experiment_dir\"\n",
        "train_writer = SummaryWriter(os.path.join(LOG_DIR, \"train\"))\n",
        "val_writer = SummaryWriter(os.path.join(LOG_DIR, \"val\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSE1DCyqxjnP"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7UcEj9v2d42"
      },
      "source": [
        "cost = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjdaBqTe2d42"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-8)\n",
        "\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftNdlyUc9x-x"
      },
      "source": [
        "N_batches_val = 66\n",
        "epochs=60\n",
        "snt_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCf0SfuND8bO"
      },
      "source": [
        "## Training the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYOw9BCi9ht0"
      },
      "source": [
        "min_valid_loss = np.inf\n",
        "for e in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()     # Optional when not using Model Specific layer\n",
        "    for i in range(N_batches):\n",
        "        [inp,target]=batch_gen(batch_size,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict)\n",
        "        inp = inp.to(device)\n",
        "        target = target.type(torch.LongTensor)\n",
        "        target = target.to(device)\n",
        "        output = model(inp)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = cost(output,target)\n",
        "        train_writer.add_scalar(\"Loss/Train\", loss, e)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss = loss.item()\n",
        "    \n",
        "    valid_loss = 0.0\n",
        "    model.eval()     # Optional when not using Model Specific layer\n",
        "    for i in range(N_batches_val):\n",
        "        [inp,target]=batch_gen(batch_size,data_folder,wav_lst_val,snt_val,wlen,lab_dict)\n",
        "        inp = inp.to(device)\n",
        "        target = target.type(torch.LongTensor)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output = model(inp)\n",
        "        loss = cost(output,target)\n",
        "        val_writer.add_scalar(\"Loss/Val\", loss, e)\n",
        "        valid_loss = loss.item()\n",
        "\n",
        "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss:.6f} \\t\\t Validation Loss: {valid_loss:.6f}')\n",
        "    if min_valid_loss > valid_loss:\n",
        "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
        "        min_valid_loss = valid_loss\n",
        "        # Saving State Dict\n",
        "        torch.save(model.state_dict(), 'SincConv_model.pth')\n",
        "    # scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShJ96wF6r8du"
      },
      "source": [
        "train_writer.close()\n",
        "val_writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7T26Dn-h_FF"
      },
      "source": [
        "%tensorboard --logdir experiment_dir/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v36_fWn9EFbT"
      },
      "source": [
        "# Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f62HUg6sH4Xs"
      },
      "source": [
        "N_batches_te=165"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKmCaYOi52eF"
      },
      "source": [
        "accuracy=[]\n",
        "def test(model, epoch):\n",
        "    samples=0\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for i in range(N_batches_te):\n",
        "        [data,target]=batch_gen(batch_size,data_folder,wav_lst_te,snt_te,wlen,lab_dict)\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        pred = pred=torch.max(output,dim=1)[1]\n",
        "        \n",
        "        correct+= (pred == target).float().sum() \n",
        "        samples = samples + (1*len(data))\n",
        "        # update progress bar\n",
        "        # pbar.update(pbar_update)\n",
        "    accuracy.append(correct/(batch_size*N_batches_te))\n",
        "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{(batch_size*N_batches_te)} ({100. * correct /(batch_size*N_batches_te):.2f}%)\\n\")\n",
        "    # print(samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHeNaZ2XijfI"
      },
      "source": [
        "model=sinc_conv_model.to(device)\n",
        "model.load_state_dict(torch.load('Trained_Models/SincConv_model.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzQUf3qSFo3y"
      },
      "source": [
        "for i in range(5):\n",
        "  test(model, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZM-ijEJ31dH"
      },
      "source": [
        "# Removal of Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OMWyhxL38f0"
      },
      "source": [
        "sinc_conv_model_4block = torch.nn.Sequential(\n",
        "    SincConvBlock(c=40, k=101, s=8),\n",
        "    DSConvBlock(40,160,25,2), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    torch.nn.AvgPool1d(30),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(160,35),\n",
        "    torch.nn.Softmax(dim=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k9J8B4V5AEQ"
      },
      "source": [
        "summary(sinc_conv_model_4block, input_data=[inp])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Brbgvm4YX5"
      },
      "source": [
        "sinc_conv_model_4block=sinc_conv_model_4block.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3qVK8Mm38oj"
      },
      "source": [
        "n = count_parameters(sinc_conv_model_4block)\n",
        "print(\"Number of parameters: %s\" % n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUNp_0va38sc"
      },
      "source": [
        "optimizer = optim.Adam(sinc_conv_model_4block.parameters(), lr=lr, eps=1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzgXViKI38yY"
      },
      "source": [
        "min_valid_loss = np.inf\n",
        "for e in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    sinc_conv_model_4block.train()     # Optional when not using Model Specific layer\n",
        "    for i in range(N_batches):\n",
        "        [inp,target]=batch_gen(batch_size,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict)\n",
        "        inp = inp.to(device)\n",
        "        target = target.type(torch.LongTensor)\n",
        "        target = target.to(device)\n",
        "        output = sinc_conv_model_4block(inp)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = cost(output,target)\n",
        "        # train_writer.add_scalar(\"Loss/Train\", loss, e)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss = loss.item()\n",
        "    \n",
        "    valid_loss = 0.0\n",
        "    sinc_conv_model_4block.eval()     # Optional when not using Model Specific layer\n",
        "    for i in range(N_batches_val):\n",
        "        [inp,target]=batch_gen(batch_size,data_folder,wav_lst_val,snt_val,wlen,lab_dict)\n",
        "        inp = inp.to(device)\n",
        "        target = target.type(torch.LongTensor)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output = sinc_conv_model_4block(inp)\n",
        "        loss = cost(output,target)\n",
        "        # val_writer.add_scalar(\"Loss/Val\", loss, e)\n",
        "        valid_loss = loss.item()\n",
        "\n",
        "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss:.6f} \\t\\t Validation Loss: {valid_loss:.6f}')\n",
        "    if min_valid_loss > valid_loss:\n",
        "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
        "        min_valid_loss = valid_loss\n",
        "        # Saving State Dict\n",
        "        torch.save(sinc_conv_model_4block.state_dict(), 'SincConvModel4.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLuo3go2j1kq"
      },
      "source": [
        "## Testing 4 block model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm4n8ypyKa8a"
      },
      "source": [
        "sinc_conv_model_4block = sinc_conv_model_4block\n",
        "sinc_conv_model_4block.load_state_dict(torch.load('Trained_Models/SincConvModel4.pth'))\n",
        "\n",
        "sinc_conv_model_4block.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfos9BsqKWDm"
      },
      "source": [
        "for i in range(5):\n",
        "  test(sinc_conv_model_4block, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X961VmuWjFez"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q6p1YLhjHW4"
      },
      "source": [
        "# Addition of Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzhnrDpCNsBh"
      },
      "source": [
        "sinc_conv_model_6block = torch.nn.Sequential(\n",
        "    SincConvBlock(c=40, k=101, s=8),\n",
        "    DSConvBlock(40,160,25,2), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1), \n",
        "    DSConvBlock(160,160,9,1),\n",
        "    DSConvBlock(160,160,9,1),\n",
        "    DSConvBlock(160,160,9,1),   \n",
        "    torch.nn.AvgPool1d(7),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(160,35),\n",
        "    torch.nn.Softmax(dim=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t5ElxE5N1gf"
      },
      "source": [
        "n = count_parameters(sinc_conv_model_6block)\n",
        "print(\"Number of parameters: %s\" % n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqDN-XdBk2pF"
      },
      "source": [
        "# Loading and testing 6 block model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7KaXVkbjgui"
      },
      "source": [
        "sinc_conv_model_6block=sinc_conv_model_6block.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmcHK2rwk7i9"
      },
      "source": [
        "sinc_conv_model_6block.load_state_dict(torch.load('Trained_Models/6layerSincConv.pth'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hCGh-JDk7YR"
      },
      "source": [
        "for i in range(5):\n",
        "  test(sinc_conv_model_4block, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKss0Xa_2d42"
      },
      "source": [
        "### Tracing 5block model for use on netron.app"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ9yUFph2d45"
      },
      "source": [
        "sinc_conv_model.eval()\n",
        "model_input = (inp)\n",
        "traced_model = torch.jit.trace(sinc_conv_model, model_input)\n",
        "print(traced_model)\n",
        "traced_model.save('traced.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}